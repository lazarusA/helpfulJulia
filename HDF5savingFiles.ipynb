{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/a/a0/HDF_logo.svg\" align=\"right\" width=\"20%\">\n",
    "\n",
    "## Julia HDF5  and JLD\n",
    "[Lázaro Alonso](https://lazarusa.github.io/Webpage/index.html)\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hierarchical Data Format (HDF) is a set of file formats (HDF4, HDF5) designed to store and organize large amounts of data. Originally developed at the National Center for Supercomputing Applications, it is supported by The HDF Group, a non-profit corporation whose mission is to ensure continued development of HDF5 technologies and the continued accessibility of data stored in HDF.\n",
    "\n",
    "- https://en.wikipedia.org/wiki/Hierarchical_Data_Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "* [HDF5](#HDF5)\n",
    "\t* [Write and read file](#Blocked-Algorithms)\n",
    "\t* [Open file](#Exercise:--Compute-the-mean-using-a-blocked-algorithm)\n",
    "\t\t* [Read complete file](#Exercise:--Compute-the-mean)\n",
    "\t\t* [Read slices](#Example)\n",
    "\t* [Storing big arrays incrementally](#Exercise:--Meteorological-data)\n",
    "\t\t* [Open-close method](#Exercise:--Subsample-and-store)\n",
    "        * [Open-do-file method](#Exercise:--Subsample-and-store)\n",
    "* [JLD](#Example:-Lennard-Jones-potential)\n",
    "\t* [save](#Dask-version)\n",
    "\t* [open](#Profiling)\n",
    "    * [read](#Exercise:--Subsample-and-store)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> HDF5 stands for Hierarchical Data Format v5 and is closely modeled on file systems. In HDF5, a \"group\" is analogous to a directory, a \"dataset\" is like a file. HDF5 also uses \"attributes\" to associate metadata with a particular group or dataset. \n",
    "- https://github.com/JuliaIO/HDF5.jl\n",
    "- https://github.com/JuliaIO/HDF5.jl/blob/master/doc/hdf5.md\n",
    "- https://github.com/JuliaIO/JLD.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "using HDF5, JLD, Test, ProgressMeter, Pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "include(\"pkgversions.jl\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia == 1.0.0\n",
      "HDF5 == 0.10.3\n",
      "IJulia == 1.14.1\n",
      "JLD == 0.9.1\n",
      "ProgressMeter == 0.8.0\n"
     ]
    }
   ],
   "source": [
    "pkgsVersion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple writting and loading... \n",
    "Suppose that you have two arrays, and want to saved into the same file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×25 Array{Float64,2}:\n",
       " 0.0585158  0.466921   0.770585  0.500985   …  0.944522   0.405942  0.624675 \n",
       " 0.317547   0.99584    0.819705  0.711076      0.0566668  0.481621  0.184016 \n",
       " 0.04748    0.913573   0.577739  0.250829      0.0866955  0.813097  0.78869  \n",
       " 0.069968   0.159338   0.163661  0.286025      0.948984   0.880552  0.5256   \n",
       " 0.525331   0.0139734  0.602305  0.0195411     0.0854151  0.477742  0.737524 \n",
       " 0.038006   0.907323   0.821577  0.125066   …  0.713056   0.703199  0.0031019\n",
       " 0.0635439  0.633875   0.153423  0.392468      0.211248   0.769062  0.601285 \n",
       " 0.910495   0.88182    0.964707  0.71539       0.606333   0.838189  0.174696 \n",
       " 0.658424   0.0541998  0.33252   0.109155      0.139272   0.266625  0.155609 \n",
       " 0.380098   0.948958   0.235199  0.534457      0.131102   0.707169  0.993895 "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1 = rand(1000,1000)\n",
    "arr2 = rand(10,25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to save to a `h5` file is to type `h5write(\"filename.h5\", \"name\", arr1)`, where `\"name\"`(creates a dataset) is a `key` for the array `arr1` to be saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5write(\"testfile.h5\", \"arr1\", arr1) \n",
    "# @write \"testfile.h5\" arr1 \n",
    "# h5write(\"testfile.h5\", \"arr1\", arr1, \"arr2\", arr2) for several datasets at the same time \n",
    "# the first option is more specific (you can tell the name of the dataset to be saved), so I liked more. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to read (load) this file we simply type: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 Array{Float64,2}:\n",
       " 0.462136   0.363221   0.586819    …  0.215662   0.924883   0.10745  \n",
       " 0.716234   0.850832   0.372387       0.828721   0.300957   0.705052 \n",
       " 0.390847   0.942859   0.304519       0.881418   0.577672   0.466735 \n",
       " 0.61313    0.581249   0.285395       0.976312   0.274994   0.0771957\n",
       " 0.813772   0.358512   0.916714       0.881597   0.53557    0.190741 \n",
       " 0.754272   0.332333   0.765953    …  0.558702   0.43669    0.506043 \n",
       " 0.828676   0.168348   0.214055       0.683629   0.44977    0.818357 \n",
       " 0.0909521  0.851579   0.0993371      0.427194   0.191073   0.926275 \n",
       " 0.129248   0.101001   0.202388       0.05458    0.874114   0.587094 \n",
       " 0.298607   0.243584   0.00180247     0.421136   0.933622   0.68531  \n",
       " 0.97151    0.800618   0.773192    …  0.520547   0.907438   0.959663 \n",
       " 0.284999   0.932764   0.613047       0.213291   0.352155   0.835357 \n",
       " 0.367318   0.786535   0.234611       0.943516   0.861677   0.462516 \n",
       " ⋮                                 ⋱                                 \n",
       " 0.599607   0.237103   0.0470845      0.0594761  0.301439   0.650674 \n",
       " 0.732645   0.632802   0.688487       0.231856   0.898002   0.684439 \n",
       " 0.398199   0.0894092  0.0845901   …  0.957416   0.621436   0.850807 \n",
       " 0.518067   0.263536   0.224672       0.349213   0.305929   0.0639107\n",
       " 0.41834    0.489419   0.378906       0.397455   0.569868   0.874312 \n",
       " 0.377009   0.791593   0.756237       0.338565   0.805456   0.646507 \n",
       " 0.704361   0.152371   0.922986       0.241261   0.6412     0.0521914\n",
       " 0.557278   0.238186   0.406238    …  0.313504   0.0135201  0.101207 \n",
       " 0.103998   0.358797   0.0927949      0.517206   0.50425    0.270368 \n",
       " 0.876157   0.0396367  0.943969       0.969097   0.791789   0.284494 \n",
       " 0.780684   0.443196   0.40295        0.443197   0.341054   0.15579  \n",
       " 0.944506   0.652706   0.121708       0.164158   0.192988   0.392655 "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr_load = h5read(\"testfile.h5\", \"arr1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note that we need to call also the dataset of interest, `arr1`. And another way will be to `h5open` the file and then `read, dump` its content. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDF5 data file: testfile.h5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farr = h5open(\"testfile.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5File\n",
      "  id: Int64 72057594037927938\n",
      "  filename: String \"testfile.h5\"\n"
     ]
    }
   ],
   "source": [
    "dump(farr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we don't know the datasets stored in the `h5` file, then we could use `names`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"arr1\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(farr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 Array{Float64,2}:\n",
       " 0.462136   0.363221   0.586819    …  0.215662   0.924883   0.10745  \n",
       " 0.716234   0.850832   0.372387       0.828721   0.300957   0.705052 \n",
       " 0.390847   0.942859   0.304519       0.881418   0.577672   0.466735 \n",
       " 0.61313    0.581249   0.285395       0.976312   0.274994   0.0771957\n",
       " 0.813772   0.358512   0.916714       0.881597   0.53557    0.190741 \n",
       " 0.754272   0.332333   0.765953    …  0.558702   0.43669    0.506043 \n",
       " 0.828676   0.168348   0.214055       0.683629   0.44977    0.818357 \n",
       " 0.0909521  0.851579   0.0993371      0.427194   0.191073   0.926275 \n",
       " 0.129248   0.101001   0.202388       0.05458    0.874114   0.587094 \n",
       " 0.298607   0.243584   0.00180247     0.421136   0.933622   0.68531  \n",
       " 0.97151    0.800618   0.773192    …  0.520547   0.907438   0.959663 \n",
       " 0.284999   0.932764   0.613047       0.213291   0.352155   0.835357 \n",
       " 0.367318   0.786535   0.234611       0.943516   0.861677   0.462516 \n",
       " ⋮                                 ⋱                                 \n",
       " 0.599607   0.237103   0.0470845      0.0594761  0.301439   0.650674 \n",
       " 0.732645   0.632802   0.688487       0.231856   0.898002   0.684439 \n",
       " 0.398199   0.0894092  0.0845901   …  0.957416   0.621436   0.850807 \n",
       " 0.518067   0.263536   0.224672       0.349213   0.305929   0.0639107\n",
       " 0.41834    0.489419   0.378906       0.397455   0.569868   0.874312 \n",
       " 0.377009   0.791593   0.756237       0.338565   0.805456   0.646507 \n",
       " 0.704361   0.152371   0.922986       0.241261   0.6412     0.0521914\n",
       " 0.557278   0.238186   0.406238    …  0.313504   0.0135201  0.101207 \n",
       " 0.103998   0.358797   0.0927949      0.517206   0.50425    0.270368 \n",
       " 0.876157   0.0396367  0.943969       0.969097   0.791789   0.284494 \n",
       " 0.780684   0.443196   0.40295        0.443197   0.341054   0.15579  \n",
       " 0.944506   0.652706   0.121708       0.164158   0.192988   0.392655 "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readmmap(farr[\"arr1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(farr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how long does it take to read this files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.008087 seconds (32 allocations: 7.631 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time arr_load = h5read(\"testfile.h5\", \"arr1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also posible to load just a small slice from the file _(and dataset)_, useful when memory is an issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.001026 seconds (51 allocations: 4.063 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14×14 Array{Float64,2}:\n",
       " 0.850832  0.372387    0.120355   …  0.94178   0.194467  0.870404  \n",
       " 0.942859  0.304519    0.664439      0.229889  0.289218  0.716554  \n",
       " 0.581249  0.285395    0.195234      0.606101  0.684714  0.00566195\n",
       " 0.358512  0.916714    0.356562      0.319648  0.625603  0.07534   \n",
       " 0.332333  0.765953    0.366279      0.452046  0.691756  0.366683  \n",
       " 0.168348  0.214055    0.820479   …  0.801266  0.811401  0.493455  \n",
       " 0.851579  0.0993371   0.866315      0.953533  0.421952  0.484452  \n",
       " 0.101001  0.202388    0.345535      0.367557  0.98411   0.828695  \n",
       " 0.243584  0.00180247  0.669277      0.789936  0.699234  0.498496  \n",
       " 0.800618  0.773192    0.216155      0.147724  0.8814    0.719916  \n",
       " 0.932764  0.613047    0.0584236  …  0.150815  0.517029  0.38775   \n",
       " 0.786535  0.234611    0.959086      0.171457  0.216337  0.0448354 \n",
       " 0.657302  0.675079    0.313684      0.290919  0.600572  0.312164  \n",
       " 0.252983  0.933837    0.971975      0.119775  0.363436  0.401983  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time data = h5read(\"testfile.h5\", \"arr1\", (2:15, 2:15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving a new dataset in the same file is really easy, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5write(\"testfile.h5\", \"arr2\", arr2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDF5 data file: testfile.h5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "farr2 = h5open(\"testfile.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Array{String,1}:\n",
       " \"arr1\"\n",
       " \"arr2\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(farr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10×25 Array{Float64,2}:\n",
       " 0.0585158  0.466921   0.770585  0.500985   …  0.944522   0.405942  0.624675 \n",
       " 0.317547   0.99584    0.819705  0.711076      0.0566668  0.481621  0.184016 \n",
       " 0.04748    0.913573   0.577739  0.250829      0.0866955  0.813097  0.78869  \n",
       " 0.069968   0.159338   0.163661  0.286025      0.948984   0.880552  0.5256   \n",
       " 0.525331   0.0139734  0.602305  0.0195411     0.0854151  0.477742  0.737524 \n",
       " 0.038006   0.907323   0.821577  0.125066   …  0.713056   0.703199  0.0031019\n",
       " 0.0635439  0.633875   0.153423  0.392468      0.211248   0.769062  0.601285 \n",
       " 0.910495   0.88182    0.964707  0.71539       0.606333   0.838189  0.174696 \n",
       " 0.658424   0.0541998  0.33252   0.109155      0.139272   0.266625  0.155609 \n",
       " 0.380098   0.948958   0.235199  0.534457      0.131102   0.707169  0.993895 "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read(farr2[\"arr2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(farr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing big arrays incrementally... \n",
    "This is useful to incrementally save to very large datasets you don't want to keep in memory.\n",
    "\n",
    "Here, first let's define a function to get the file size of our files, as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "szprint (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function szprint(szfile)\n",
    "    if szfile <= 10^6\n",
    "        println(\"File size = $(szfile/10^3) KB\")\n",
    "    elseif 10^6 < szfile <= 10^9\n",
    "        println(\"File size = $(szfile/10^6) MB\")\n",
    "    elseif 10^9 < szfile <= 10^12\n",
    "        println(\"File size = $(szfile/10^9) GB\")\n",
    "    elseif 10^12 < szfile <= 10^15\n",
    "        println(\"File size = $(szfile/10^12) TB\")\n",
    "    else\n",
    "        println(\"File size is really big. Petabytes or more!\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size = 700.001 MB\n"
     ]
    }
   ],
   "source": [
    "szprint(700001000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The argument is `szfile = filesize(\"filename.h5\")`, which gives you a `byte` count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here, I will show two ways to do it.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File size = 8.002048 MB\n"
     ]
    }
   ],
   "source": [
    "f = h5open(\"incrementalFilev1.h5\", \"w\")\n",
    "dset_A = d_create(f,\"arr1\",datatype(Float64), dataspace(10^6,1))\n",
    "for i in 1:10^4:10^6\n",
    "    dset_A[i:i + 10^4 - 1,1] = rand(10^4)\n",
    "    szfile = filesize(\"incrementalFilev1.h5\")\n",
    "    szprint(szfile)\n",
    "    sleep(.1)\n",
    "    IJulia.clear_output(true)\n",
    "end\n",
    "flush(f)\n",
    "close(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this method you always need to `close` the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "szprintp (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function szprintp(szfile)\n",
    "    if szfile <= 10^6\n",
    "        return (szfile/10^3, \"KB\") \n",
    "    elseif 10^6 < szfile <= 10^9\n",
    "        return (szfile/10^6, \"MB\")\n",
    "    elseif 10^9 < szfile <= 10^12\n",
    "        return (szfile/10^9, \"GB\")\n",
    "    elseif 10^12 < szfile <= 10^15\n",
    "        return(szfile/10^12, \"TB\")\n",
    "    else\n",
    "        return (\"=> Petabytes\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, \"KB\")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "szprintp(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second option "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "\u001b[K\u001b[A\r",
      "\u001b[34mSaving...100%|██████████████████████████████████████████| Time: 0:00:11\u001b[39m\n",
      "\u001b[34m  Filesize:  (8.002048, \"MB\")\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "h5open(\"incrementalFilev2.h5\", \"w\") do file\n",
    "    dset = d_create(file, \"arr1k\", datatype(Float64), dataspace(10^6,1))\n",
    "    p = Progress(100, dt=0.1, desc=\"Saving...\", color=:blue)\n",
    "    for iter in 1:10^4:10^6\n",
    "        dset[iter:iter + 10^4 - 1,1] = rand(10^4)\n",
    "        szfile = filesize(\"incrementalFilev2.h5\")        \n",
    "        ProgressMeter.next!(p; showvalues = [(:Filesize, szprintp(szfile))])\n",
    "        sleep(0.1)\n",
    "        IJulia.clear_output(true)\n",
    "    end\n",
    "    end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and, using the `do` method there is no need for closing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, let's read  some of  files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDF5 data file: incrementalFilev1.h5"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = h5open(\"incrementalFilev1.h5\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"arr1\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000×1 Array{Float64,2}:\n",
       " 0.5894602638501172 \n",
       " 0.4184764328371329 \n",
       " 0.439757133232755  \n",
       " 0.48351324327234546\n",
       " 0.0803237890638866 \n",
       " 0.2800074718410055 \n",
       " 0.29435621582954297\n",
       " 0.7790651181756039 \n",
       " 0.5452231923974442 \n",
       " 0.3201954906219213 \n",
       " 0.6008114467899888 \n",
       " 0.2227568611082542 \n",
       " 0.4012946570840701 \n",
       " ⋮                  \n",
       " 0.2800807684963549 \n",
       " 0.03433193720859573\n",
       " 0.6105182059639942 \n",
       " 0.7690635630025138 \n",
       " 0.08902317967935702\n",
       " 0.5829474472490959 \n",
       " 0.07238830013505937\n",
       " 0.769639914822033  \n",
       " 0.02367084838587652\n",
       " 0.6953015780950993 \n",
       " 0.449456799661053  \n",
       " 0.9786655141740772 "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_mmaped = readmmap(f1[\"arr1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In my daily workflow I usually need to save matrices, a lot! So, this is how I do it, _(additional options, like chuncks and compress are also available)..._ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose I want to save $100$ realizations where the output in each case is a $100\\times100$ matrix, then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand(100,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\r",
      "\u001b[K\u001b[A\r",
      "\u001b[34mSaving...100%|██████████████████████████████████████████| Time: 0:00:11\u001b[39m\n",
      "\u001b[34m  File_Size:  (8.002048, \"MB\")\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "fm = h5open(\"MatrixFile.h5\", \"w\")\n",
    "dset_fm = d_create(fm,\"arraym\",datatype(Float64), dataspace(100,100,100)) #, \"chunk\", (100,100,1))\n",
    "p = Progress(100, dt=0.1, desc=\"Saving...\", color=:blue)\n",
    "for i in 1:100\n",
    "    dset_fm[:, :, i] = rand(100,100)\n",
    "    szfilem = filesize(\"MatrixFile.h5\")\n",
    "    ProgressMeter.next!(p; showvalues = [(:File_Size, szprintp(szfilem))])\n",
    "    sleep(0.1)\n",
    "    IJulia.clear_output(true)\n",
    "end\n",
    "flush(fm)\n",
    "close(fm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes `chunking` improves efficiency if you write or extract small segments or slices from an array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HDF5 data file: MatrixFile.h5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmatrix = h5open(\"MatrixFile.h5\", \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"arraym\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(fmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(fmatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×100×1 Array{Float64,3}:\n",
       "[:, :, 1] =\n",
       " 0.928248  0.0696589  0.931383   …  0.904124   0.843308    0.914293 \n",
       " 0.108408  0.964235   0.948981      0.900878   0.00742996  0.355971 \n",
       " 0.426537  0.393569   0.852943      0.401384   0.411922    0.724338 \n",
       " 0.171431  0.743979   0.939311      0.941813   0.889796    0.0774215\n",
       " 0.91756   0.843584   0.222655      0.24704    0.730844    0.397121 \n",
       " 0.3682    0.492465   0.980167   …  0.407092   0.61815     0.724063 \n",
       " 0.773456  0.572464   0.0536272     0.740469   0.377556    0.0030069\n",
       " 0.906614  0.047466   0.772832      0.875563   0.268535    0.645895 \n",
       " 0.539327  0.169885   0.777984      0.0979376  0.106558    0.502408 \n",
       " 0.754408  0.326626   0.897094      0.406862   0.114632    0.712558 \n",
       " 0.979511  0.63735    0.3329     …  0.569844   0.684612    0.923897 \n",
       " 0.201261  0.538277   0.58591       0.430929   0.019732    0.784963 \n",
       " 0.2028    0.179967   0.300326      0.199255   0.0817853   0.0937971\n",
       " ⋮                               ⋱                                  \n",
       " 0.563157  0.125069   0.910984      0.300844   0.953247    0.685555 \n",
       " 0.552799  0.258036   0.895256      0.815121   0.00680069  0.46602  \n",
       " 0.604698  0.893516   0.0418002  …  0.0666205  0.454633    0.197588 \n",
       " 0.164171  0.575557   0.608331      0.986388   0.940739    0.731739 \n",
       " 0.351158  0.177632   0.359231      0.931652   0.87631     0.298621 \n",
       " 0.373886  0.690206   0.0163316     0.588789   0.514077    0.116928 \n",
       " 0.130229  0.7493     0.517329      0.861041   0.499552    0.926647 \n",
       " 0.405202  0.66854    0.246288   …  0.493546   0.771349    0.125531 \n",
       " 0.470186  0.993882   0.35087       0.513597   0.353927    0.611908 \n",
       " 0.901274  0.665045   0.13409       0.803464   0.496166    0.70741  \n",
       " 0.277808  0.687229   0.86735       0.135878   0.709744    0.933298 \n",
       " 0.482182  0.566883   0.402022      0.804134   0.382668    0.259712 "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h5read(\"MatrixFile.h5\", \"arraym\", (:, :, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JLD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"testfile.jld\", \"arr1\", arr1)\n",
    "#@save \"testfile.jld\" arr1\n",
    "# again, I prefer the first option, just for control. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Julia data file version 0.1.2: testfile.jld"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openfile = jldopen(\"testfile.jld\",\"r\", mmaparrays=true)\n",
    "#load(\"testfile.jld\", \"arr1\")\n",
    "#@load \"testfile.jld\" arr1\n",
    "# eval(:arr1)\n",
    "# these last options are also valid, but for big files the first option is better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the `jld` file is open it is also posible to access small slices, to avoid  memory issues. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.144443 seconds (205.12 k allocations: 10.180 MiB, 10.17% gc time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15×4 Array{Float64,2}:\n",
       " 0.363221  0.586819    0.84582    0.0462436\n",
       " 0.850832  0.372387    0.120355   0.0970798\n",
       " 0.942859  0.304519    0.664439   0.120625 \n",
       " 0.581249  0.285395    0.195234   0.61301  \n",
       " 0.358512  0.916714    0.356562   0.388615 \n",
       " 0.332333  0.765953    0.366279   0.305589 \n",
       " 0.168348  0.214055    0.820479   0.74564  \n",
       " 0.851579  0.0993371   0.866315   0.939746 \n",
       " 0.101001  0.202388    0.345535   0.142217 \n",
       " 0.243584  0.00180247  0.669277   0.837023 \n",
       " 0.800618  0.773192    0.216155   0.0456821\n",
       " 0.932764  0.613047    0.0584236  0.557297 \n",
       " 0.786535  0.234611    0.959086   0.474546 \n",
       " 0.657302  0.675079    0.313684   0.802757 \n",
       " 0.252983  0.933837    0.971975   0.569784 "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time read(openfile[\"arr1\"])[1:15, 2:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Symbol,1}:\n",
       " :arr1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@load \"testfile.jld\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can inspect the names(datasets) stored in this file as "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{String,1}:\n",
       " \"arr1\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "close(openfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://discourse.julialang.org/t/how-to-read-range-of-jld-file/954/6\n",
    "- https://github.com/timholy/ProgressMeter.jl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing big arrays incrementally... JLD version, waiting for `d_create` for JLD. Currenly just `g_create` is available. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
